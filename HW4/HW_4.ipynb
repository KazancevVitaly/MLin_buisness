{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95044eff",
   "metadata": {},
   "source": [
    "# GeekBrains\n",
    "## Машинное обучение в бизнесе\n",
    "## ДЗ Урока 4 (Uplift-моделирование)\n",
    "### Виталий Казанцев"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f30b730",
   "metadata": {},
   "source": [
    "#### Т/з\n",
    "1. скачать набор данных маркетинговых кампаний отсюда https://www.kaggle.com/davinwijaya/customer-retention\n",
    "2. там поле conversion - это целевая переменная, а offer - коммуникация. Переименовать поля (conversion -> target, offer -> treatment) и привести поле treatment к бинарному виду (1 или 0, т.е было какое-то предложение или нет) - значение No Offer означает отсутствие коммуникации, а все остальные - наличие.\n",
    "3. сделать разбиение набора данных не тренировочную и тестовую выборки\n",
    "4. сделать feature engineering на ваше усмотрение (допускается свобода выбора методов)\n",
    "5. провести uplift-моделирование 3 способами: одна модель с признаком коммуникации (S learner), модель с трансформацией таргета (трансформация классов п. 2. 1) и вариант с двумя независимыми моделями\n",
    "6. в конце вывести единую таблицу сравнения метрик uplift@10%, uplift@20% этих 3 моделей\n",
    "7. построить модель UpliftTreeClassifier и попытаться описать словами полученное дерево\n",
    "8. (опционально) для модели S learner (модель с дополнительным признаком коммуникации) построить зависимость таргета (конверсии - поле conversion) от значения uplift: 1) сделать прогноз и получить uplift для тестовой выборки 2) отсортировать тестовую выборку по uplift по убыванию 3) разбить на децили (pandas qcut вам в помощь) 4) для каждого дециля посчитать среднюю conversion\n",
    "9. (опционально) построить модель UpliftRandomForestClassifier и попытаться описать словами полученное дерево"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b1628b",
   "metadata": {},
   "source": [
    "__Задание 1__  \n",
    "скачать набор данных маркетинговых кампаний отсюда https://www.kaggle.com/davinwijaya/customer-retention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8583eecb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "sklearn.tree._tree.TreeBuilder size changed, may indicate binary incompatibility. Expected 80 from C header, got 72 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_66526/399426825.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklift\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSoloModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mClassTransformation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTwoModels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcausalml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUpliftTreeClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUpliftRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcausalml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muplift_tree_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muplift_tree_plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venvLDS/lib/python3.9/site-packages/causalml/inference/tree/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcausal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcausaltree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCausalTreeRegressor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCausalRandomForestRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muplift_tree_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muplift_tree_plot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_dist_tree_leaves_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0muplift\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecisionTree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUpliftTreeClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUpliftRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m from .utils import (\n\u001b[1;32m      5\u001b[0m     \u001b[0mcat_group\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venvLDS/lib/python3.9/site-packages/causalml/inference/tree/causal/causaltree.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcausalml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_treatment_vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_tree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseCausalDecisionTree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_tree_leaves_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venvLDS/lib/python3.9/site-packages/causalml/inference/tree/causal/_tree.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_check_sample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDepthFirstCausalTreeBuilder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStandardMSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCausalMSE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mcausalml/inference/tree/causal/builder.pyx\u001b[0m in \u001b[0;36minit causalml.inference.tree.causal.builder\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: sklearn.tree._tree.TreeBuilder size changed, may indicate binary incompatibility. Expected 80 from C header, got 72 from PyObject"
     ]
    }
   ],
   "source": [
    "import pandas as pd; pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklift.metrics import uplift_at_k\n",
    "from sklift.viz import plot_uplift_preds\n",
    "from sklift.models import SoloModel, ClassTransformation, TwoModels\n",
    "\n",
    "from causalml.inference.tree import UpliftTreeClassifier, UpliftRandomForestClassifier\n",
    "from causalml.inference.tree import uplift_tree_string, uplift_tree_plot\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7117eae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b895267",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549f7035",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5044f7f",
   "metadata": {},
   "source": [
    "__Задание 2__  \n",
    "там поле conversion - это целевая переменная, а offer - коммуникация. Переименовать поля (conversion -> target, offer -> treatment) и привести поле treatment к бинарному виду (1 или 0, т.е было какое-то предложение или нет) - значение No Offer означает отсутствие коммуникации, а все остальные - наличие."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf99bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'conversion': 'target', 'offer': 'treatment'}, inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b448d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df.treatment != 'No Offer'), 'treatment'] = 1\n",
    "df.loc[(df.treatment == 'No Offer'), 'treatment'] = 0\n",
    "df = df.astype({'treatment': np.int8})\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f427500",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62c88f6",
   "metadata": {},
   "source": [
    "__Задание 3__  \n",
    "сделать разбиение набора данных не тренировочную и тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfe4d46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, treat_train, treat_test = train_test_split(df.drop(columns=['target']), \n",
    "                                                            df['target'],\n",
    "                                                            df['treatment'],\n",
    "                                                            random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape, treat_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d424922",
   "metadata": {},
   "source": [
    "__Задание 4__  \n",
    "сделать feature engineering на ваше усмотрение (допускается свобода выбора методов)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7becd1ee",
   "metadata": {},
   "source": [
    "Разделим пользователей по объему расходов(expenses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ed2330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expenses(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df['is_whale'] = 0\n",
    "    df['is_dolphin'] = 0\n",
    "    df['is_minnow'] = 0\n",
    "    df.loc[df['history'] >= 1000, 'is_whale'] = 1\n",
    "    df.loc[(df['history'] < 1000) & (df['history'] >= 200), 'is_dolphin'] = 1\n",
    "    df.loc[df['history'] < 200, 'is_minnow'] = 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945f9ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = expenses(X_train)\n",
    "X_test = expenses(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe76993",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b53af6",
   "metadata": {},
   "source": [
    "__Задание 5__  \n",
    "провести uplift-моделирование 3 способами: одна модель с признаком коммуникации (S learner), модель с трансформацией таргета (трансформация классов п. 2. 1) и вариант с двумя независимыми моделями  \n",
    "__Задание 6__  \n",
    "в конце вывести единую таблицу сравнения метрик uplift@10%, uplift@20% этих 3 моделей\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf412bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(columns=['uplift@10%', 'uplift@20%'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ca6e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SoloModel(CatBoostClassifier(iterations=20, thread_count=2, random_state=42, silent=True))\n",
    "sm = sm.fit(X_train, y_train, treat_train, estimator_fit_params={'cat_features': cat_features})\n",
    "\n",
    "uplift_sm = sm.predict(X_test)\n",
    "print(uplift_sm)\n",
    "\n",
    "sm_score_10 = uplift_at_k(y_true=y_test, uplift=uplift_sm, treatment=treat_test, strategy='by_group', k=0.1)\n",
    "sm_score_20 = uplift_at_k(y_true=y_test, uplift=uplift_sm, treatment=treat_test, strategy='by_group', k=0.2)\n",
    "\n",
    "metrics_df = metrics_df.append({'uplift@10%': sm_score_10, 'uplift@20%': sm_score_20}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28671b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ClassTransformation(CatBoostClassifier(iterations=20, thread_count=2, random_state=42, silent=True))\n",
    "ct = ct.fit(X_train, y_train, treat_train, estimator_fit_params={'cat_features': cat_features})\n",
    "\n",
    "uplift_ct = ct.predict(X_test)\n",
    "print(uplift_ct)\n",
    "\n",
    "ct_score_10 = uplift_at_k(y_true=y_test, uplift=uplift_ct, treatment=treat_test, strategy='by_group', k=0.1)\n",
    "ct_score_20 = uplift_at_k(y_true=y_test, uplift=uplift_ct, treatment=treat_test, strategy='by_group', k=0.2)\n",
    "\n",
    "metrics_df = metrics_df.append({'uplift@10%': ct_score_10, 'uplift@20%': ct_score_20}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4cd5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = TwoModels(\n",
    "    estimator_trmnt=CatBoostClassifier(iterations=20, thread_count=2, random_state=42, silent=True), \n",
    "    estimator_ctrl=CatBoostClassifier(iterations=20, thread_count=2, random_state=42, silent=True), \n",
    "    method='vanilla'\n",
    ")\n",
    "tm = tm.fit(\n",
    "    X_train, y_train, treat_train,\n",
    "    estimator_trmnt_fit_params={'cat_features': cat_features}, \n",
    "    estimator_ctrl_fit_params={'cat_features': cat_features}\n",
    ")\n",
    "\n",
    "uplift_tm = tm.predict(X_test)\n",
    "print(uplift_tm)\n",
    "\n",
    "tm_score_10 = uplift_at_k(y_true=y_test, uplift=uplift_tm, treatment=treat_test, strategy='by_group', k=0.1)\n",
    "tm_score_20 = uplift_at_k(y_true=y_test, uplift=uplift_tm, treatment=treat_test, strategy='by_group', k=0.2)\n",
    "\n",
    "metrics_df = metrics_df.append({'uplift@10%': tm_score_10, 'uplift@20%': tm_score_20}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51b14ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.index = ['Solo Learner', 'Transform Learner', 'Two Model Learner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6641228b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
